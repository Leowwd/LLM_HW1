{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f4d1651",
   "metadata": {},
   "source": [
    "# N-Gram, RNN and LSTM Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c7e1a",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "139c9f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(filepath: str):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.strip().lower().split() for line in lines]\n",
    "\n",
    "dir_root = \"/Users/leo_liao/Desktop/LLM_HW1/\"\n",
    "\n",
    "training_corpus = load_corpus(dir_root + \"train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d4fd5",
   "metadata": {},
   "source": [
    "## Build N-gram Language Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9cf58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "class NGramLanguageModel:\n",
    "    def __init__(self, n, smoothing=0.01):\n",
    "        \"\"\"\n",
    "        Initialize N-gram language model\n",
    "        Args:\n",
    "            n: The value of n for n-grams (2 for bigram, 3 for trigram)\n",
    "            smoothing: Smoothing parameter (Laplace/add-k smoothing)\n",
    "        \"\"\"\n",
    "        self.n = n\n",
    "        self.smoothing = smoothing\n",
    "        self.n_gram_counts = None\n",
    "        self.n_minus_1_gram_counts = None\n",
    "        self.vocab = set()\n",
    "    \n",
    "    def n_gram_distribution(self, tokenized_corpus, n=2):\n",
    "\n",
    "        if n < 2:\n",
    "            raise ValueError(\"n must be larger than 1\")\n",
    "\n",
    "        n_minus_1_gram_counts = defaultdict(int)\n",
    "        n_gram_counts = defaultdict(int)\n",
    "\n",
    "        for sentence in tokenized_corpus:\n",
    "            if len(sentence) < n:\n",
    "                continue\n",
    "            \n",
    "            for i in range(len(sentence) - n + 1):\n",
    "                n_gram = tuple(sentence[i : i + n])\n",
    "                n_minus_1_gram = tuple(sentence[i : i + n - 1])\n",
    "                \n",
    "                n_minus_1_gram_counts[n_minus_1_gram] += 1\n",
    "                n_gram_counts[n_gram] += 1\n",
    "                \n",
    "        return n_minus_1_gram_counts, n_gram_counts\n",
    "\n",
    "    def train(self, tokenized_corpus):\n",
    "        \"\"\"Train the n-gram model on a tokenized corpus\"\"\"\n",
    "        print(f\"Training {self.n}-gram model...\")\n",
    "        \n",
    "        # Get n-gram counts\n",
    "        self.n_minus_1_gram_counts, self.n_gram_counts = self.n_gram_distribution(\n",
    "            tokenized_corpus, self.n\n",
    "        )\n",
    "        \n",
    "        # Build vocabulary\n",
    "        for sentence in tokenized_corpus:\n",
    "            self.vocab.update(sentence)\n",
    "        \n",
    "        print(f\"Vocabulary size: {len(self.vocab)}\")\n",
    "        print(f\"{self.n-1}-gram types: {len(self.n_minus_1_gram_counts)}\")\n",
    "        print(f\"{self.n}-gram types: {len(self.n_gram_counts)}\")\n",
    "        \n",
    "    def get_probability(self, n_gram):\n",
    "        \"\"\"\n",
    "        Calculate the probability of an n-gram with smoothing\n",
    "        P(wn | w1...wn-1) = (count(w1...wn) + smoothing) / (count(w1...wn-1) + smoothing * V)\n",
    "        \"\"\"\n",
    "        if len(n_gram) != self.n:\n",
    "            raise ValueError(f\"Expected {self.n}-gram, got {len(n_gram)}-gram\")\n",
    "        \n",
    "        context = tuple(n_gram[:-1])  # n-1 gram (context)\n",
    "        \n",
    "        numerator = self.n_gram_counts.get(tuple(n_gram), 0) + self.smoothing\n",
    "        denominator = self.n_minus_1_gram_counts.get(context, 0) + self.smoothing * len(self.vocab)\n",
    "        \n",
    "        return numerator / denominator\n",
    "    \n",
    "    def predict_next_word(self, context, top_k=5):\n",
    "        \"\"\"\n",
    "        Predict the most likely next word given a context\n",
    "        Args:\n",
    "            context: tuple of n-1 words\n",
    "            top_k: return top k predictions\n",
    "        Returns:\n",
    "            List of (word, probability) tuples\n",
    "        \"\"\"\n",
    "        if len(context) != self.n - 1:\n",
    "            raise ValueError(f\"Context should have {self.n-1} words\")\n",
    "        \n",
    "        context = tuple(context)\n",
    "        candidates = []\n",
    "        \n",
    "        # Find all n-grams that start with this context\n",
    "        for n_gram, count in self.n_gram_counts.items():\n",
    "            if n_gram[:-1] == context:\n",
    "                word = n_gram[-1]\n",
    "                prob = self.get_probability(n_gram)\n",
    "                candidates.append((word, prob))\n",
    "        \n",
    "        # Sort by probability\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return candidates[:top_k]\n",
    "    \n",
    "    def generate_sentence(self, start_words, max_length=20):\n",
    "        \"\"\"\n",
    "        Generate a sentence starting with given words\n",
    "        Args:\n",
    "            start_words: List of starting words (should be n-1 words)\n",
    "            max_length: Maximum length of generated sentence\n",
    "            sampling: If True, sample from distribution; if False, take most likely\n",
    "        Returns:\n",
    "            Generated sentence as a list of words\n",
    "        \"\"\"\n",
    "        if len(start_words) < self.n - 1:\n",
    "            raise ValueError(f\"Need at least {self.n-1} starting words\")\n",
    "        \n",
    "        sentence = list(start_words)\n",
    "        \n",
    "        while len(sentence) < max_length:\n",
    "            context = tuple(sentence[-(self.n-1):])\n",
    "            candidates = self.predict_next_word(context, top_k=1)\n",
    "            \n",
    "            if not candidates:\n",
    "                # No predictions available, stop\n",
    "                break\n",
    "            \n",
    "            # Take the most likely word\n",
    "            next_word = candidates[0][0]\n",
    "            \n",
    "            sentence.append(next_word)\n",
    "        \n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1398cffa",
   "metadata": {},
   "source": [
    "## (a) Train Models and Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcaa994",
   "metadata": {},
   "source": [
    "### Load test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc9cd054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test corpus size: 649918 sentences\n",
      "First 3 test sentences: [['test', 'for', 'doneness'], ['add', 'cabbage', 'and', 'carrots'], ['add', 'onion', 'and', 'cook', 'until', 'golden', 'brown']]\n"
     ]
    }
   ],
   "source": [
    "test_corpus = load_corpus(dir_root + \"test.txt\")\n",
    "print(f\"Test corpus size: {len(test_corpus)} sentences\")\n",
    "print(f\"First 3 test sentences: {test_corpus[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5618a6",
   "metadata": {},
   "source": [
    "### Train Bigram Model (n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9853e187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BIGRAM MODEL (n=2)\n",
      "============================================================\n",
      "Training 2-gram model...\n",
      "Building context index for fast prediction...\n",
      "Vocabulary size: 63069\n",
      "1-gram types: 55827\n",
      "2-gram types: 707454\n",
      "\n",
      "Training time: 8.37 seconds\n",
      "Building context index for fast prediction...\n",
      "Vocabulary size: 63069\n",
      "1-gram types: 55827\n",
      "2-gram types: 707454\n",
      "\n",
      "Training time: 8.37 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BIGRAM MODEL (n=2)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "bigram_model = NGramLanguageModel(n=2, smoothing=0.01)\n",
    "\n",
    "start_time = time.time()\n",
    "bigram_model.train(training_corpus)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTraining time: {train_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9ff914",
   "metadata": {},
   "source": [
    "### Train Trigram Model (n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3665e46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRIGRAM MODEL (n=3)\n",
      "============================================================\n",
      "Training 3-gram model...\n",
      "Vocabulary size: 63069\n",
      "2-gram types: 622841\n",
      "3-gram types: 2353735\n",
      "\n",
      "Training time: 11.55 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRIGRAM MODEL (n=3)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "trigram_model = NGramLanguageModel(n=3, smoothing=0.01)\n",
    "\n",
    "start_time = time.time()\n",
    "trigram_model.train(training_corpus)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nTraining time: {train_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087a18a9",
   "metadata": {},
   "source": [
    "### Evaluate Models on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31579a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_test_accuracy(model, test_corpus):\n",
    "    \"\"\"\n",
    "    Calculate prediction accuracy on test set\n",
    "    For each n-gram in test sentences, predict the next word and check if it matches\n",
    "    \"\"\"\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    print(f\"Processing {len(test_corpus)} sentences...\")\n",
    "    \n",
    "    for sent_idx, sentence in enumerate(test_corpus):\n",
    "        if len(sentence) < model.n:\n",
    "            continue\n",
    "        \n",
    "        if (sent_idx + 1) % 10000 == 0:\n",
    "            print(f\"  Processed {sent_idx + 1}/{len(test_corpus)} sentences... \"\n",
    "                  f\"Current accuracy: {correct_predictions}/{total_predictions} \"\n",
    "                  f\"({100*correct_predictions/total_predictions if total_predictions > 0 else 0:.2f}%)\")\n",
    "        \n",
    "        for i in range(len(sentence) - model.n + 1):\n",
    "            # Get context and actual next word\n",
    "            context = tuple(sentence[i : i + model.n - 1])\n",
    "            actual_word = sentence[i + model.n - 1]\n",
    "            \n",
    "            # Predict next word\n",
    "            candidates = model.predict_next_word(context, top_k=1)\n",
    "            \n",
    "            if candidates:\n",
    "                predicted_word = candidates[0][0]\n",
    "                if predicted_word == actual_word:\n",
    "                    correct_predictions += 1\n",
    "            \n",
    "            total_predictions += 1\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    return accuracy, correct_predictions, total_predictions\n",
    "\n",
    "# Evaluate Bigram Model\n",
    "# print(\"=\" * 60)\n",
    "# print(\"EVALUATING BIGRAM MODEL ON TEST SET\")\n",
    "# print(\"=\" * 60)\n",
    "\n",
    "# bigram_accuracy, bigram_correct, bigram_total = calculate_test_accuracy(bigram_model, test_corpus)\n",
    "# print(f\"\\nBigram Model Results:\")\n",
    "# print(f\"  Correct Predictions: {bigram_correct} / {bigram_total}\")\n",
    "# print(f\"  Accuracy: {bigram_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f49c6928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING TRIGRAM MODEL ON TEST SET\n",
      "============================================================\n",
      "Processing 649918 sentences...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEVALUATING TRIGRAM MODEL ON TEST SET\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m trigram_accuracy, trigram_correct, trigram_total \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_test_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrigram_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_corpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTrigram Model Results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Correct Predictions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrigram_correct\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrigram_total\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[29], line 26\u001b[0m, in \u001b[0;36mcalculate_test_accuracy\u001b[0;34m(model, test_corpus)\u001b[0m\n\u001b[1;32m     23\u001b[0m actual_word \u001b[38;5;241m=\u001b[39m sentence[i \u001b[38;5;241m+\u001b[39m model\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Predict next word\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_next_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m candidates:\n\u001b[1;32m     29\u001b[0m     predicted_word \u001b[38;5;241m=\u001b[39m candidates[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[25], line 89\u001b[0m, in \u001b[0;36mNGramLanguageModel.predict_next_word\u001b[0;34m(self, context, top_k)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Find all n-grams that start with this context\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_gram, count \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_gram_counts\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mn_gram\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m context:\n\u001b[1;32m     90\u001b[0m         word \u001b[38;5;241m=\u001b[39m n_gram[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     91\u001b[0m         prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_probability(n_gram)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate Trigram Model\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EVALUATING TRIGRAM MODEL ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "trigram_accuracy, trigram_correct, trigram_total = calculate_test_accuracy(trigram_model, test_corpus)\n",
    "print(f\"\\nTrigram Model Results:\")\n",
    "print(f\"  Correct Predictions: {trigram_correct} / {trigram_total}\")\n",
    "print(f\"  Accuracy: {trigram_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Model Performance\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON ON TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nAccuracy Comparison:\")\n",
    "print(f\"  Bigram Model:  {bigram_accuracy * 100:.2f}%\")\n",
    "print(f\"  Trigram Model: {trigram_accuracy * 100:.2f}%\")\n",
    "\n",
    "improvement = (trigram_accuracy - bigram_accuracy) * 100\n",
    "print(f\"\\nAccuracy Improvement: {improvement:+.2f}%\")\n",
    "\n",
    "if trigram_accuracy > bigram_accuracy:\n",
    "    print(f\"Trigram model performs better (higher accuracy)\")\n",
    "elif trigram_accuracy < bigram_accuracy:\n",
    "    print(f\"Bigram model performs better (may be due to data sparsity)\")\n",
    "else:\n",
    "    print(f\"= Both models have the same accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d675ad",
   "metadata": {},
   "source": [
    "## (b) Hardware Usage Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a612e7d",
   "metadata": {},
   "source": [
    "在training的時候發現memory佔比會比較高，並且都是用一個cpu跑的，但gpu卻是不會用到的，因為我們沒有用pytorch之類的gpu加速套件。\n",
    "但是速度還是非常快的。\n",
    "反之，testing的時候memory佔比高且時間非常的長。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9e3f0d",
   "metadata": {},
   "source": [
    "## (c) Sentence Completion with Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3a40721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incomplete sentences: 10\n"
     ]
    }
   ],
   "source": [
    "# Load incomplete sentences\n",
    "incomplete_sentences = load_corpus(dir_root + \"incomplete.txt\")\n",
    "\n",
    "print(f\"Number of incomplete sentences: {len(incomplete_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e4d096f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SENTENCE COMPLETION USING TRIGRAM MODEL\n",
      "================================================================================\n",
      "\n",
      "Sentence 1:\n",
      "  Incomplete: cover with\n",
      "  Completed:  cover with foil and bake for about 5 minutes or until the mixture into the pan and bake for about\n",
      "  Length: 20 words\n",
      "\n",
      "Sentence 2:\n",
      "  Incomplete: roll up\n",
      "  Completed:  roll up and place in a large bowl and mix well and set aside to cool completely on wire rack\n",
      "  Length: 20 words\n",
      "\n",
      "Sentence 3:\n",
      "  Incomplete: cook the\n",
      "  Completed:  cook the pasta and cook for about 5 minutes or until the mixture into the pan and bake for about\n",
      "  Length: 20 words\n",
      "\n",
      "Sentence 4:\n",
      "  Incomplete: stir in\n",
      "  Completed:  stir in the center of the pan and bake for about 5 minutes or until the mixture into the pan\n",
      "  Length: 20 words\n",
      "\n",
      "Sentence 5:\n",
      "  Incomplete: spread out\n",
      "  Completed:  spread out on a baking sheet and bake for about 5 minutes or until the mixture into the pan and\n",
      "  Length: 20 words\n",
      "\n",
      "Sentence 6:\n",
      "  Incomplete: transfer the\n",
      "  Completed:  transfer the mixture into the pan and bake for about 5 minutes or until the mixture into the pan and\n",
      "  Length: 20 words\n",
      "\n",
      "Sentence 7:\n",
      "  Incomplete: put the\n",
      "  Completed:  put the chicken and cook for about 5 minutes or until the mixture into the pan and bake for about\n",
      "  Length: 20 words\n",
      "\n",
      "Sentence 8:\n",
      "  Incomplete: push the\n",
      "  Completed:  push the dough into a large bowl and mix well and set aside to cool completely on wire rack to\n",
      "  Length: 20 words\n",
      "\n",
      "Sentence 9:\n",
      "  Incomplete: cut into\n",
      "  Completed:  cut into squares and serve with a fork and serve with a fork and serve with a fork and serve\n",
      "  Length: 20 words\n",
      "\n",
      "Sentence 10:\n",
      "  Incomplete: toss the\n",
      "  Completed:  toss the salad and toss to coat the bottom of the pan and bake for about 5 minutes or until\n",
      "  Length: 20 words\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Complete sentences using the trigram model\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SENTENCE COMPLETION USING TRIGRAM MODEL\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "completed_sentences = []\n",
    "\n",
    "for i, incomplete in enumerate(incomplete_sentences, 1):\n",
    "    print(f\"Sentence {i}:\")\n",
    "    print(f\"  Incomplete: {' '.join(incomplete)}\")\n",
    "    \n",
    "    # Generate completion\n",
    "    completed = trigram_model.generate_sentence(incomplete, max_length=20)\n",
    "    completed_sentences.append(completed)\n",
    "    \n",
    "    print(f\"  Completed:  {' '.join(completed)}\")\n",
    "    print(f\"  Length: {len(completed)} words\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "habitat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
